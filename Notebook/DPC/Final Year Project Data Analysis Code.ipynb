{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperspy.api as hs\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import scipy as sc\n",
    "import scipy.io as sio\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab qt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Signal "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathFile = \"D:/Users/Don/IntensityImages__C16_15_24_151205_030__2015_12_12_01/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gainMapFile = \"D:/Users/Don/Gain Map/GainMap_FZJ_80keV_binning2_gain2.mat\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "newFileName = \"Any_name\" #Name of hdf5 file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_signal(pathFile, gainMapFile, newFileName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Performing Decomposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = newFileName + \".hdf5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_decomposition(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1st Operation: Systematic error shift contribution cancellation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_1 = hs.load(\"Sample_1.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_2 = hs.load(\"Sample_2.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nbr = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_nbr_2 = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Align relative to ref data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Translation_mat = align2D_cv_2stacks(sample_1, sample_2, cv2.MOTION_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Lorentz_STEM_'+str(file_nbr)+'_ref_shift.npy', Translation_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Positive Bias\n",
    "plot_save('Lorentz_STEM_'+str(file_nbr), 'ref_shift', sample_1.axes_manager[1].size, sample_1.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Negative Bias\n",
    "plot_save_2('Lorentz_STEM_'+str(file_nbr), 'ref_shift', sample_2.axes_manager[1].size, sample_2.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2nd Operation: Plotting field map with mean inner potential shift contribution cancelled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Positive Bias\n",
    "plot_save_3('Lorentz_STEM_'+str(file_nbr), 'Lorentz_STEM_'+str(file_nbr_2), \\\n",
    "            'ref_shift', sample_1.axes_manager[1].size, sample_1.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For Negative Bias\n",
    "plot_save_4('Lorentz_STEM_'+str(file_nbr), 'Lorentz_STEM_'+str(file_nbr_2), \\\n",
    "            'ref_shift', sample_2.axes_manager[1].size, sample_2.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To view the figures and signals of the solar cell dataset \n",
    "\n",
    "def save_signal(pathFile, gainMapFile, newFileName):\n",
    "    dataDir = pathfile\n",
    "    mats = []\n",
    "    for file in os.listdir(dataDir):\n",
    "        mats.append(sio.loadmat(dataDir+file))\n",
    "        \n",
    "    for n in range (lens(mats)):\n",
    "        mats[n] = np.swapaxes(mats[n]['a3Image16'],2,0)\n",
    "        \n",
    "    Temp = np.memmap('Temporary_memory.mymemmap', dtype = 'float32', mode = 'w+', \\\n",
    "                     shape = (256,256,264,132))\n",
    "\n",
    "    Temp_2 = np.memmap('Temporary_memory_2.mymemmap', dtype = 'float32', mode = 'w+', \\\n",
    "                       shape = (65536,264,132))\n",
    "    \n",
    "    arr = (mats[0], mats[1], mats[2], mats[3],mats[4],mats[5],mats[6],mats[7],mats[8],mats[9],\\\n",
    "           mats[10],mats[11],mats[12],mats[13])\n",
    "    Temp_2 = np.vstack(arr)\n",
    "    \n",
    "    if gainMap:\n",
    "        gain_map = gainMapFile\n",
    "        gain_map_1 = sio.loadmat(gain_map)\n",
    "        gain_map_1 = gain_map_1['GainMap']\n",
    "        gain_map_1 = np.swapaxes(gain_map_1,0,1)\n",
    "        \n",
    "        for n in range (65536):\n",
    "            Temp_2[n] = np.multiply(Temp_2[n], gain_map_1)\n",
    "        \n",
    "        for i in range(int((np.size(Temp_2,0)/256)+1)):\n",
    "            for j in range(256):\n",
    "                if (i*256 + j) >= np.size(Temp_2,0):\n",
    "                    End_i = i\n",
    "                    End_j = j\n",
    "                    break\n",
    "                else:\n",
    "                    Temp[i][j][:] = Temp_2[i*256+j][:]\n",
    "                \n",
    "    \n",
    "    else:\n",
    "        for i in range(int((np.size(Temp_2,0)/256)+1)):\n",
    "            for j in range(256):\n",
    "                if (i*256 + j) >= np.size(Temp_2,0):\n",
    "                    End_i = i\n",
    "                    End_j = j\n",
    "                    break\n",
    "                else:\n",
    "                    Temp[i][j][:] = Temp_2[i*256+j][:]\n",
    "                    \n",
    "    #Plotting the signal\n",
    "    \n",
    "    Signal2D = hs.signals.Signal2D(Temp).as_lazy()\n",
    "    Signal2D.plot()\n",
    "    print (\"Save the signal plot? Y/N \")\n",
    "    x = input()\n",
    "    if x == \"Y\":\n",
    "        Signal2D.save(newFileName + 'hdf5')\n",
    "    else:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    del Temp\n",
    "    del Temp_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To perform decomposition on the dataset\n",
    "\n",
    "def run_decomposition(sample):\n",
    "    sample = hs.load(sample)\n",
    "    sample.plot()\n",
    "    \n",
    "    print(\"Do you want to plot the region of interest? Y/N \")\n",
    "    Answer = input()\n",
    "    if Answer == \"Y\":\n",
    "        print(\"Enter the coordinate for a, b, c ,d:\")\n",
    "        a = int(input(\"a: \"))\n",
    "        b = int(input(\"b: \"))\n",
    "        c = int(input(\"c: \"))\n",
    "        d = int(input(\"d: \"))\n",
    "        ROI = hs.roi.RectangularROI(left = a, right = b, top = c, bottom = d)\n",
    "        IMC = ROI.interactive(sample)\n",
    "        IMC.plot()\n",
    "        IMC.decompostion()\n",
    "    else:\n",
    "        sample.decomposition()\n",
    "        \n",
    "    print (\"Do you want to plot the \\\"Scree Plot\\\"? Y/N \")\n",
    "    Answer_2 = input ()\n",
    "    Answer_3 = int(input(\"How many components you wish to be mentioned in the scree plot? \"))\n",
    "    Answer_4 = int(input(\"How many components do you wish to plot? \"))\n",
    "    if Answer_2 == \"Y\":\n",
    "        if sample:\n",
    "            ax = sample.plot_explained_variance_ratio(xaxis_type = 'number', n = Answer_3)\n",
    "            sc = sample.get_decomposition_model(Answer_4)\n",
    "            sc.plot()\n",
    "        elif IMC:\n",
    "            ax = IMC.plot_explained_variance_ratio(xaxis_type= 'number', n = Answer_3)\n",
    "            sc = IMC.get_decomposition_model(Answer_4)\n",
    "            sc.plot()\n",
    "        else:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align2D_cv_2stacks(hs_stack1, hs_stack2, warp_mode):\n",
    "    \n",
    "    hs_stack1.change_dtype('float32')\n",
    "    hs_stack2.change_dtype('float32')\n",
    "    \n",
    "    hs_stack1.unfold_navigation_space()\n",
    "    hs_stack2.unfold_navigation_space()\n",
    "         \n",
    "    # High pass filter using low pass and Gaussian blurring\n",
    "    filter_1 = ndimage.gaussian_filter(hs_stack1.data[0], 10)\n",
    "    # Convert Numpy hpf data in openCV format (3 channels)\n",
    "    img_1_hpf_cv = cv2.cvtColor(filter_1, cv2.COLOR_GRAY2BGR)\n",
    "    # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "    img_1_hpf_cv = cv2.cvtColor(img_1_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    #find the shape\n",
    "    sz = img_1_hpf_cv.shape\n",
    "    \n",
    "    # Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "        warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "    else :\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        \n",
    "    warp_matrix_returned = np.empty((hs_stack1.data.shape[0], warp_matrix.shape[0], warp_matrix.shape[1]))\n",
    "    \n",
    "    # Specify the number of iterations.\n",
    "    number_of_iterations = 3000;\n",
    "    \n",
    "    # Specify the threshold of the increment\n",
    "    termination_eps = 1e-10;\n",
    "    \n",
    "    # Define termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)\n",
    "\n",
    "    for i in range (0,hs_stack1.data.shape[0]):\n",
    "        # High pass filter using low pass and Gaussian blurring \n",
    "        filter_1 = ndimage.gaussian_filter(hs_stack1.data[i], 10)\n",
    "        # Convert Numpy hpf data in openCV format (3 channels)\n",
    "        img_1_hpf_cv = cv2.cvtColor(filter_1, cv2.COLOR_GRAY2BGR)\n",
    "        # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "        img_1_hpf_cv = cv2.cvtColor(img_1_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        ### Idem for ref data\n",
    "        # High pass filter using low pass and Gaussian blurring         \n",
    "        filter_2 = ndimage.gaussian_filter(hs_stack2.data[i], 10)\n",
    "        # Convert Numpy hpf data in openCV format (3 channels)\n",
    "        img_2_hpf_cv = cv2.cvtColor(filter_2, cv2.COLOR_GRAY2BGR)\n",
    "        # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "        img_2_hpf_cv = cv2.cvtColor(img_2_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "        (cc, warp_matrix) = cv2.findTransformECC(img_1_hpf_cv,img_2_hpf_cv,warp_matrix, warp_mode, criteria, None, 1)\n",
    "    \n",
    "        warp_matrix_returned[i,:,:] = warp_matrix\n",
    "        \n",
    "        print(str(i) +' / '+str(hs_stack1.data.shape[0]-1))\n",
    "              \n",
    "    hs_stack1.fold()\n",
    "    hs_stack2.fold()\n",
    "    \n",
    "    return warp_matrix_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Field Map for 1st Operation: Systematic error contribution cancellation (for positive bias)\n",
    "\n",
    "def plot_save(path_analysis, typeal, sizex, sizey):\n",
    "\n",
    "    if  typeal == 'relative_shift' or \\\n",
    "        typeal == 'ref_relative_shift' or \\\n",
    "        typeal == 'ref_shift':\n",
    "            Translation_mat = np.load(path_analysis + '_' + typeal + '.npy')\n",
    "            Translation_mat_square = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat = Translation_mat_square[:,:,:,2]\n",
    "    else:\n",
    "        print('pb')\n",
    "            \n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            M[i,j] =np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "        \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, M, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, Shift_mat[:,:,1]/M[Mi_max,Mj_max], Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis + '_' + typeal +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting Field Map for 1st Operation: Systematic error contribution cancellation (for negative bias)\n",
    "\n",
    "def plot_save_2(path_analysis, typeal, sizex, sizey):\n",
    "\n",
    "    if  typeal == 'relative_shift' or \\\n",
    "        typeal == 'ref_relative_shift' or \\\n",
    "        typeal == 'ref_shift':\n",
    "            Translation_mat = np.load(path_analysis + '_' + typeal + '.npy')\n",
    "            Translation_mat_square = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat = Translation_mat_square[:,:,:,2]\n",
    "    else:\n",
    "        print('pb')\n",
    "            \n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            M[i,j] =np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "                    \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, M, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, -Shift_mat[:,:,1]/M[Mi_max,Mj_max], -Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis + '_' + typeal +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Field Map for 2nd Operation: Mean inner potential shift contribution cancellation (for positive bias)\n",
    "\n",
    "def plot_save_3(path_analysis, path_analysis2, typeal, sizex, sizey):\n",
    "    \n",
    "    if  typeal == 'relative_shift' or \\\n",
    "        typeal == 'ref_relative_shift' or \\\n",
    "        typeal == 'ref_shift':\n",
    "            Translation_mat = np.load(path_analysis + '_' + typeal + '.npy')\n",
    "            Translation_mat_square = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat = Translation_mat_square[:,:,:,2]\n",
    "            \n",
    "            Translation_mat_2 = np.load(path_analysis2 + '_' + typeal + '.npy')\n",
    "            Translation_mat_square_2 = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat_2 = Translation_mat_square[:,:,:,2]\n",
    "    else:\n",
    "        print('pb')\n",
    "    \n",
    "    N = np.empty_like(Shift_mat[:,:,0])\n",
    "    L = np.empty_like(Shift_mat[:,:,0])\n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            N[i,j] = np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "            L[i,j] = np.sqrt(np.power(Shift_mat_2[i,j,0],2)+np.power(Shift_mat_2[i,j,1],2))\n",
    "            M[i,j] = N[i,j] - L[i,j]\n",
    "        \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, M, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, Shift_mat[:,:,1]/M[Mi_max,Mj_max], Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis + '_' + typeal + '2.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting Field Map for 2nd Operation: Mean inner potential shift contribution cancellation (for negative bias)\n",
    "\n",
    "def plot_save_4(path_analysis, path_analysis2, typeal, sizex, sizey):\n",
    "    \n",
    "    if  typeal == 'relative_shift' or \\\n",
    "        typeal == 'ref_relative_shift' or \\\n",
    "        typeal == 'ref_shift':\n",
    "            Translation_mat = np.load(path_analysis + '_' + typeal + '.npy')\n",
    "            Translation_mat_square = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat = Translation_mat_square[:,:,:,2]\n",
    "            \n",
    "            Translation_mat_2 = np.load(path_analysis2 + '_' + typeal + '.npy')\n",
    "            Translation_mat_square_2 = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat_2 = Translation_mat_square[:,:,:,2]\n",
    "    else:\n",
    "        print('pb')\n",
    "    \n",
    "    N = np.empty_like(Shift_mat[:,:,0])\n",
    "    L = np.empty_like(Shift_mat[:,:,0])\n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            N[i,j] = np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "            L[i,j] = np.sqrt(np.power(Shift_mat_2[i,j,0],2)+np.power(Shift_mat_2[i,j,1],2))\n",
    "            M[i,j] = N[i,j] - L[i,j]\n",
    "        \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, M, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, -Shift_mat[:,:,1]/M[Mi_max,Mj_max], -Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis + '_' + typeal + '2.png', dpi=300)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
