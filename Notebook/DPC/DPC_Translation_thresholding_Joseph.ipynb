{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "from scipy import interpolate\n",
    "from scipy import ndimage\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as pp\n",
    "from scipy.optimize import curve_fit\n",
    "\n",
    "mpl.rcParams['axes.linewidth'] = 3.0 #set the value globally\n",
    "#mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as pp\n",
    "from scipy.optimize import curve_fit\n",
    "from scipy import ndimage\n",
    "\n",
    "mpl.rcParams['axes.linewidth'] = 3.0 #set the value globally\n",
    "#mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperspy.api as hs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Files loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_img = 'Diffraction SI'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No file name matches this pattern",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-72f448ebf364>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mTEM2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mhs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath_img\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;34m'.dm4'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\lib\\site-packages\\hyperspy\\io.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(filenames, signal_type, stack, stack_axis, new_axis_name, lazy, convert_units, **kwds)\u001b[0m\n\u001b[0;32m    215\u001b[0m                                if os.path.isfile(f)])\n\u001b[0;32m    216\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mfilenames\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 217\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'No file name matches this pattern'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    218\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    219\u001b[0m         raise ValueError(\n",
      "\u001b[1;31mValueError\u001b[0m: No file name matches this pattern"
     ]
    }
   ],
   "source": [
    "TEM2 = hs.load(path_img+'.dm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.axes_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.crop_image(top=-700.,left=-700.,bottom=800.,right=800.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_mean = np.mean(TEM2.data)\n",
    "TEM2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.data[TEM2.data> 10*TEM2_mean] = TEM2_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.unfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold = TEM2.deepcopy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.unfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins_histo = 5000\n",
    "i=0\n",
    "data_point2 =440 # estimate of the x pixel at the minimun between the 2 peaks in the histogram of data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "plt.plot(np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1][0:-1], \\\n",
    "         np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "plt.plot(np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_fun1c(x, a1, mu1, sigma1):\n",
    "    return a1*np.exp(-(x-mu1)**2/sigma1**2)\n",
    "\n",
    "x = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1][0:data_point2]\n",
    "y = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][0:data_point2]\n",
    "params = curve_fit(fit_func1, x, y, (4000,30,100))\n",
    "[a10, mu10, sigma10] = params[0]\n",
    "\n",
    "y_new = fit_func1(x, a10, mu10, sigma10)\n",
    "\n",
    "plt.plot(x,y,x,y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func(x, a2, mu2, sigma2):\n",
    "    return a2*np.exp(-(x-mu2)**2/sigma2**2)\n",
    "\n",
    "x = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1][data_point2:-1]\n",
    "y = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point2:]\n",
    "\n",
    "maxx = np.argmax(np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point2:])\n",
    "maxy = x[maxx]\n",
    "\n",
    "data_point3 = data_point2\n",
    "while maxx < 20 or x[maxx] < mu1: \n",
    "    data_point3 = data_point3 + 20\n",
    "    maxx = np.argmax(np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point3:])\n",
    "    maxy = x[maxx]\n",
    "    \n",
    "#x = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1][data_point3:-1]\n",
    "#y = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point3:]\n",
    "\n",
    "#params = curve_fit(fit_func, x, y, (1000,maxy,100))\n",
    "[a20, mu20, sigma20] = params[0]\n",
    "\n",
    "y_new = fit_func(x, a20, mu20, sigma20)\n",
    "\n",
    "plt.plot(x,y,x,y_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_func1(x, a1, mu1, sigma1):\n",
    "    return a1*np.exp(-(x-mu1)**2/sigma1**2)\n",
    "def fit_func2(x, a2, mu2, sigma2):\n",
    "    return a2*np.exp(-(x-mu2)**2/sigma2**2)\n",
    "def fit_func(x, a1, mu1, sigma1, a2, mu2, sigma2):\n",
    "    return a1*np.exp(-(x-mu1)**2/sigma1**2)+a2*np.exp(-(x-mu2)**2/sigma2**2)\n",
    "\n",
    "a1, mu1, sigma1, a2, mu2, sigma2 = a10, mu10, sigma10, a20, mu20, sigma20\n",
    "for i in range(1740,TEM2_threshold.data.shape[0]):\n",
    "    if i == 127 or i == 129 or i == 241 or i == 361 or i == 369 or i == 420 or i == 481\\\n",
    "        or i == 489 or i == 541 or i == 550 or i == 608 or i == 667 or i == 669 or i == 723\\\n",
    "        or i == 724 or i == 727 or i == 729 or i == 784or i == 784 or i == 788 or i == 790\\\n",
    "        or i == 840 or i == 841 or i == 847 or i == 849 or i == 850 or i == 900 or i == 902\\\n",
    "        or i == 908 or i == 963 or i == 1023 or i == 1026  or i == 1027 or i == 1030 or i == 1031\\\n",
    "        or i == 1085 or i == 1090 or i == 1146 or i == 1147 or i == 1151 or i == 1207 or i == 1208\\\n",
    "        or i == 1209 or i == 1210 or i == 1263 or i == 1269 or i == 1322 or i == 1323 or i == 1326\\\n",
    "        or i == 1382 or i == 1383 or i == 1385 or i == 1388 or i == 1389 or i == 1390 or i == 1391\\\n",
    "        or i == 1440 or i == 1444 or i == 1446 or i == 1447 or i == 1500 or i == 1502 or i == 1504\\\n",
    "        or i == 1505 or i == 1507 or i == 1509 or i == 1600 or i == 1620 or i == 1621 or i == 1622\\\n",
    "        or i == 1629 or i == 1631 or i == 1632 or i == 1680 or i == 1684 or i == 1688 or i == 1689\\\n",
    "        or i == 1692 or i == 1742 or i == 1745 or i == 1746 or i == 1749 or i == 1750:\n",
    "        TEM2.data[i] = TEM2.data[i-1]\n",
    "    x = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1]\\\n",
    "        [0:np.histogram(TEM2.data[0],density=False, bins=bins_histo)[0].size]\n",
    "    y = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0]\n",
    " \n",
    "    ### Fit the 1st peak\n",
    "    x1 = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1][0:data_point2]\n",
    "    y1 = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][0:data_point2]\n",
    "    params = curve_fit(fit_func1, x1, y1, (a10, mu1, sigma10))\n",
    "    [a1, mu1, sigma1] = params[0]\n",
    "    \n",
    "    ### Fit the 2nd peak\n",
    "    x2 = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1][data_point2:-1]\n",
    "    y2 = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point2:]\n",
    "\n",
    "    maxx = np.argmax(np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point2:])\n",
    "    maxy = x2[maxx]\n",
    "\n",
    "    data_point3 = data_point2\n",
    "    while maxx < 20 or x2[maxx] <= mu1: \n",
    "        data_point3 = data_point3 + 20\n",
    "        maxx = np.argmax(np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point3:])\n",
    "    \n",
    "    x2 = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[1][data_point3:-1]\n",
    "    y2 = np.histogram(TEM2.data[i],density=False, bins=bins_histo)[0][data_point3:]\n",
    "\n",
    "    params = curve_fit(fit_func2, x2, y2, (a20, x2[maxx], sigma20))\n",
    "    [a2, mu2, sigma2] = params[0]\n",
    "       \n",
    "    y_new = fit_func(x, a1, mu1, sigma1, a2, mu2, sigma2)\n",
    "    y2 = y_new[x>np.min((mu1,mu2))]\n",
    "    x2 = x[x>np.min((mu1,mu2))]\n",
    "    y3 = y2[x2<np.max((mu1,mu2))]\n",
    "    x3 = x2[x2<np.max((mu1,mu2))]\n",
    "               \n",
    "    print(i, mu1, mu2, x3[y3 == np.min(y3)][0])\n",
    "    TEM2_threshold.data[i][TEM2.data[i]>=x3[y3 == np.min(y3)][0]]=1 \n",
    "    TEM2_threshold.data[i][TEM2.data[i]<x3[y3 == np.min(y3)][0]]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a1, mu1, sigma1, a2, mu2, sigma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.fold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.unfold()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.save(path_img + 'threshold_ini.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold = hs.load(path_img + 'threshold_ini.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.axes_manager[0].offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.axes_manager[1].offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.axes_manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.crop(axis=0, start=20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2_threshold.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.axes_manager[0].offset = 0\n",
    "TEM2.axes_manager[1].offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.crop(axis=0, start=20.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment of threshold data (Translation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Translation_mat = align2D_cv(TEM2_threshold, cv2.MOTION_TRANSLATION) #aligned versus pixel=30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_img+'_Theshold+Translation_ini.npy', \\\n",
    "        np.reshape(Translation_mat, (TEM2_threshold.axes_manager[1].size, TEM2_threshold.axes_manager[0].size,2,3))[:,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save_angle(path_img+'_Theshold+Translation_ini', \\\n",
    "                       TEM2_threshold.axes_manager[1].size, TEM2_threshold.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Alignment of original data (Translation) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Translation_mat = align2D_cv(TEM2, cv2.MOTION_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_img+'_Translation.npy', \\\n",
    "        np.reshape(Translation_mat, (TEM2.axes_manager[1].size, TEM2.axes_manager[0].size,2,3))[:,:,:,2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save_angle(path_img+'_Translation', \\\n",
    "                       TEM2.axes_manager[1].size, TEM2.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### COM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COM = np.empty((TEM2.axes_manager[1].size,TEM2.axes_manager[0].size,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_origin = ndimage.measurements.center_of_mass(TEM2_threshold.data[0,0])[0]\n",
    "Y_origin = ndimage.measurements.center_of_mass(TEM2_threshold.data[0,0])[1]\n",
    "\n",
    "for i in range(0,TEM2.axes_manager[1].size):\n",
    "    for j in range(0,TEM2.axes_manager[0].size):\n",
    "        COM[i,j,0] = ndimage.measurements.center_of_mass(TEM2_threshold.data[i,j])[0]-X_origin\n",
    "        COM[i,j,1] = ndimage.measurements.center_of_mass(TEM2_threshold.data[i,j])[1]-Y_origin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ndimage.measurements.center_of_mass(TEM2_threshold.data[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_img+'_COM.npy', COM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save_angle(path_img, 'COM', TEM2.axes_manager[1].size, TEM2.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COM_mean = np.empty((TEM2.axes_manager[1].size,TEM2.axes_manager[0].size,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COM_mean[:,:,0] = COM[:,:,0] - np.mean(COM[:,:,0])\n",
    "COM_mean[:,:,1] = COM[:,:,1] - np.mean(COM[:,:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_img+'_COM-mean.npy', COM_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save_angle(path_img, 'COM-mean', TEM2.axes_manager[1].size, TEM2.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COM_flatten = np.empty((TEM2.axes_manager[1].size,TEM2.axes_manager[0].size,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-COM[:,:,0].shape[0]/2, COM[:,:,0].shape[0]/2, COM[:,:,0].shape[0])\n",
    "y = np.linspace(-COM[:,:,0].shape[1]/2, COM[:,:,0].shape[1]/2, COM[:,:,0].shape[1])\n",
    "X, Y = np.meshgrid(x, -y, copy=False)\n",
    "Z = COM_mean[:,:,0] #X**2 + Y**2 + np.random.rand(*X.shape)*0.01\n",
    "\n",
    "X = X.flatten()\n",
    "Y = Y.flatten()\n",
    "\n",
    "A = np.array([X*0+1, X, Y]).T #,X**2, X**2*Y, X**2*Y**2, Y**2, X*Y**2, X*Y \n",
    "B = Z.flatten()\n",
    "\n",
    "c, r, rank, s = np.linalg.lstsq(A, B, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COM_flatten[:,:,0] = COM_mean[:,:,0] -(c[0] + x*c[1] + y*c[2] )\n",
    "#x**2*c[3] + x**2*y*c[4] + x**2*y**2*c[5] + y**2*c[6] + x*y**2*c[7] + x*y*c[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-COM[:,:,1].shape[0]/2, COM[:,:,1].shape[0]/2, COM[:,:,1].shape[0])\n",
    "y = np.linspace(-COM[:,:,1].shape[1]/2, COM[:,:,1].shape[1]/2, COM[:,:,1].shape[1])\n",
    "X, Y = np.meshgrid(x, -y, copy=False)\n",
    "Z = COM_mean[:,:,1] #X**2 + Y**2 + np.random.rand(*X.shape)*0.01\n",
    "\n",
    "X = X.flatten()\n",
    "Y = Y.flatten()\n",
    "\n",
    "A = np.array([X*0+1, X, Y]).T #X**2, X**2*Y, X**2*Y**2, Y**2, X*Y**2 , X*Y\n",
    "B = Z.flatten()\n",
    "\n",
    "c, r, rank, s = np.linalg.lstsq(A, B, rcond=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "COM_flatten[:,:,1] = COM_mean[:,:,1] -(c[0] + x*c[1] + y*c[2] )\n",
    "#x**2*c[3] + x**2*y*c[4] + x**2*y**2*c[5] + y**2*c[6] + x*y**2*c[7] + x*y*c[8] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(path_img+'_COM+flatten.npy', COM_flatten)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save_angle(path_img, 'COM+flatten', TEM2.axes_manager[1].size, TEM2.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax.quiver(X, Y, COM_flatten, \\\n",
    "        units='x', width=0.15, scale=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 quadrants data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEM2.axes_manager[2].offset = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TEM2.axes_manager[3].offset = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "center = np.array((0,0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Frourquadrant_shift = np.empty((TEM2.axes_manager[1].size,TEM2.axes_manager[0].size,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ABCD_return = quadrant(TEM2.data[0,0], center)\n",
    "X_origin = ABCD_return[0]+ABCD_return[2]-(ABCD_return[1]+ABCD_return[3])\n",
    "Y_origin = ABCD_return[1]+ABCD_return[3]-(ABCD_return[0]+ABCD_return[2])\n",
    "\n",
    "for i in range(0,np.shape(Frourquadrant_shift)[0]):\n",
    "    for j in range(0,np.shape(Frourquadrant_shift)[1]):\n",
    "        ABCD_return = quadrant(TEM2.data[i,j], center)\n",
    "        Frourquadrant_shift[i,j,0] = -(ABCD_return[0]+ABCD_return[2]-(ABCD_return[1]+ABCD_return[3])-X_origin)\n",
    "        Frourquadrant_shift[i,j,1] = -(ABCD_return[1]+ABCD_return[3]-(ABCD_return[0]+ABCD_return[2])-Y_origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('Lorentz_STEM_4quadran.npy', Frourquadrant_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_save('Lorentz_STEM_4quadran', TEM2.axes_manager[1].size, TEM2.axes_manager[0].size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Commun parts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_save_angle(path_analysis, sizex, sizey):\n",
    "\n",
    "    Shift_mat = np.load(path_analysis+'.npy')\n",
    "            \n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            M[i,j] =np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "            \n",
    "    angle = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            # -> cosine of the angle\n",
    "            cosangle = np.dot((Shift_mat[i,j,0],Shift_mat[i,j,1]),(0,1)) \\\n",
    "                /np.linalg.norm((Shift_mat[i,j,0],Shift_mat[i,j,1]))\n",
    "            angle[i,j] = np.arccos(clip(cosangle, -1, 1))\n",
    "        \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, angle, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, Shift_mat[:,:,1]/M[Mi_max,Mj_max], Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_save_angle(path_analysis, typeal, sizex, sizey):\n",
    "\n",
    "    if  typeal == 'relative_shift' or \\\n",
    "        typeal == 'ref_relative_shift' or \\\n",
    "        typeal == 'ref_shift':\n",
    "            Translation_mat = np.load(path_analysis + '.npy')\n",
    "            Translation_mat_square = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat = Translation_mat_square[:,:,:,2]\n",
    "    elif typeal == 'current_hyperpsy':\n",
    "            Translation_mat = np.load(path_analysis+'.npy')\n",
    "            Shift_mat = np.reshape(Translation_mat, (sizex,sizey,2))\n",
    "    elif typeal == 'COM' or typeal == 'COM_ref' or typeal == 'COM_rel_toref' \\\n",
    "            or typeal == 'COM_variable' or typeal == 'COM-mean' or typeal == 'COM_variable_flat'\\\n",
    "            or typeal == '4quadran' or typeal == '4quadran_ref' \\\n",
    "            or typeal == '4quadran_rel_toref':\n",
    "        Shift_mat = np.load(path_analysis+'_' + typeal + '.npy')\n",
    "    else:\n",
    "        print('pb')\n",
    "            \n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            M[i,j] =np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "            \n",
    "    angle = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            # -> cosine of the angle\n",
    "            cosangle = np.dot((Shift_mat[i,j,0],Shift_mat[i,j,1]),(0,1)) \\\n",
    "                /np.linalg.norm((Shift_mat[i,j,0],Shift_mat[i,j,1]))\n",
    "            angle[i,j] = np.arccos(clip(cosangle, -1, 1))\n",
    "        \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, angle, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, Shift_mat[:,:,1]/M[Mi_max,Mj_max], Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis + typeal +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_save(path_analysis, typeal, sizex, sizey):\n",
    "\n",
    "    if  typeal == 'relative_shift' or \\\n",
    "        typeal == 'ref_relative_shift' or \\\n",
    "        typeal == 'ref_shift':\n",
    "            Translation_mat = np.load(path_analysis + '.npy')\n",
    "            Translation_mat_square = np.reshape(Translation_mat, (sizex,sizey,2,3))\n",
    "            Shift_mat = Translation_mat_square[:,:,:,2]\n",
    "    elif typeal == 'current_hyperpsy':\n",
    "            Translation_mat = np.load(path_analysis+'.npy')\n",
    "            Shift_mat = np.reshape(Translation_mat, (sizex,sizey,2))\n",
    "    elif typeal == 'COM' or typeal == 'COM_ref' or typeal == 'COM_rel_toref' \\\n",
    "            or typeal == 'COM_variable' or typeal == 'COM-mean' or typeal == 'COM_variable_flat'\\\n",
    "            or typeal == '4quadran' or typeal == '4quadran_ref' \\\n",
    "            or typeal == '4quadran_rel_toref':\n",
    "        Shift_mat = np.load(path_analysis+'_' + typeal + '.npy')\n",
    "    else:\n",
    "        print('pb')\n",
    "            \n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            M[i,j] =np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "        \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, M, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, Shift_mat[:,:,1]/M[Mi_max,Mj_max], Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_save_single(path_analysis, sizex, sizey):\n",
    "\n",
    "    Shift_mat = np.load(path_analysis+ '.npy')\n",
    "            \n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            M[i,j] =np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "        \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, M, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, Shift_mat[:,:,1]/M[Mi_max,Mj_max], Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        angles = 'xy', units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def plot_save_single(path_analysis, sizex, sizey):\n",
    "\n",
    "    Shift_mat = np.load(path_analysis+ '.npy')\n",
    "            \n",
    "    M = np.empty_like(Shift_mat[:,:,0])\n",
    "    for i in range(0,np.size(Shift_mat[:,0,0])):\n",
    "        for j in range(0,np.size(Shift_mat[i,:,0])):\n",
    "            M[i,j] =np.sqrt(np.power(Shift_mat[i,j,0],2)+np.power(Shift_mat[i,j,1],2))\n",
    "                   \n",
    "    Mi_max, Mj_max = np.unravel_index(np.argmax(M, axis=None), M.shape)\n",
    "\n",
    "    X = np.arange(-np.size(Shift_mat[0,:,0])/2, np.size(Shift_mat[0,:,0])/2, 1)\n",
    "    Y = np.arange(-np.size(Shift_mat[:,0,0])/2, np.size(Shift_mat[:,0,0])/2, 1)\n",
    "\n",
    "    fig, ax = plt.subplots(squeeze=True, figsize=(8, 8))\n",
    "\n",
    "    # Contour Plot\n",
    "    cp = plt.contourf(X, -Y, M, cmap=cm.coolwarm)\n",
    "    cb = plt.colorbar(cp)\n",
    "\n",
    "    q = ax.quiver(X, -Y, Shift_mat[:,:,1]/M[Mi_max,Mj_max], Shift_mat[:,:,0]/M[Mi_max,Mj_max], \\\n",
    "        angles = 'xy', units='x', width=0.15, scale=0.3)\n",
    "    fig.savefig(path_analysis +'.png', dpi=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align2D_cv(hs_stack, warp_mode):\n",
    "    \n",
    "    hs_stack.change_dtype('float32')\n",
    "    hs_stack.unfold_navigation_space()\n",
    "    \n",
    "    #shift\n",
    "    warp_matrix_max = np.zeros(4)\n",
    "       \n",
    "    # High pass filter using low pass and Gaussian blurring\n",
    "    filter_1 = ndimage.gaussian_filter(hs_stack.data[0], 30)\n",
    "    \n",
    "    # Convert Numpy hpf data in openCV format (3 channels)\n",
    "    img_1_hpf_cv = cv2.cvtColor(filter_1, cv2.COLOR_GRAY2BGR)\n",
    "    # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "    img_1_hpf_cv = cv2.cvtColor(img_1_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    #find the shape\n",
    "    sz = img_1_hpf_cv.shape\n",
    "    \n",
    "    #Mask, needed for findTransformECC (not in the previous version of opencv)\n",
    "    mask = np.zeros(hs_stack.data[0].shape)\n",
    "    mask[:,:] = 1\n",
    "    mask[0,0] = 0\n",
    "    \n",
    "    #Translation ( MOTION_TRANSLATION ) : The first image can be shifted ( translated ) by (x , y) to obtain the second image. There are only two parameters x and y that we need to estimate.\n",
    "    #Euclidean ( MOTION_EUCLIDEAN ) : The first image is a rotated and shifted version of the second image. So there are three parameters — x, y and angle . You will notice in Figure 4, when a square undergoes Euclidean transformation, the size does not change, parallel lines remain parallel, and right angles remain unchanged after transformation.\n",
    "    #Affine ( MOTION_AFFINE ) : An affine transform is a combination of rotation, translation ( shift ), scale, and shear. This transform has six parameters. When a square undergoes an Affine transformation, parallel lines remain parallel, but lines meeting at right angles no longer remain orthogonal.\n",
    "    #Homography ( MOTION_HOMOGRAPHY ) : All the transforms described above are 2D transforms. They do not account for 3D effects. A homography transform on the other hand can account for some 3D effects ( but not all ). This transform has 8 parameters. A square when transformed using a Homography can change to any quadrilateral.\n",
    "    \n",
    "    #warp_mode = cv2.MOTION_TRANSLATION\n",
    "    \n",
    "    # Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "        warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "    else :\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        \n",
    "    warp_matrix_returned = np.empty((hs_stack.data.shape[0], warp_matrix.shape[0], warp_matrix.shape[1]))\n",
    "    \n",
    "    # Specify the number of iterations.\n",
    "    number_of_iterations = 3000;\n",
    "    \n",
    "    # Specify the threshold of the increment\n",
    "    termination_eps = 1e-10;\n",
    "    \n",
    "    # Define termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)\n",
    "\n",
    "    for i in range (1,hs_stack.data.shape[0]):\n",
    "        filter_2 = ndimage.gaussian_filter(hs_stack.data[i], 10)\n",
    "        # Convert Numpy hpf data in openCV format (3 channels)\n",
    "        img_2_hpf_cv = cv2.cvtColor(filter_2, cv2.COLOR_GRAY2BGR)\n",
    "        # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "        img_2_hpf_cv = cv2.cvtColor(img_2_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "        (cc, warp_matrix) = cv2.findTransformECC(img_1_hpf_cv,img_2_hpf_cv,warp_matrix, warp_mode, criteria)\n",
    "    \n",
    "        warp_matrix_returned[i,:,:] = warp_matrix\n",
    "    \n",
    "#        if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "            # Use warpPerspective for Homography \n",
    "#            hs_stack.data[i] = cv2.warpPerspective (hs_stack.data[i], warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    " #       else :\n",
    "            # Use warpAffine for Translation, Euclidean and Affine\n",
    "#            hs_stack.data[i] = cv2.warpAffine(hs_stack.data[i], warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP); \n",
    "           \n",
    "#        if warp_matrix[0,2]<warp_matrix_max[0]:\n",
    "#            warp_matrix_max[0]=warp_matrix[0,2]\n",
    "            \n",
    "#        if warp_matrix[0,2]>warp_matrix_max[1]:\n",
    "#            warp_matrix_max[1]=warp_matrix[0,2]\n",
    "\n",
    " #       if warp_matrix[1,2]<warp_matrix_max[2]:\n",
    " #           warp_matrix_max[2]=warp_matrix[1,2]\n",
    "            \n",
    " #       if warp_matrix[1,2]>warp_matrix_max[3]:\n",
    "#            warp_matrix_max[3]=warp_matrix[1,2]\n",
    "            \n",
    "        print(str(i) +' / '+str(hs_stack.data.shape[0]-1))\n",
    "            \n",
    "#    hs_stack.crop_image(bottom=hs_stack.data.shape[2]-np.int(warp_matrix_max[3]), \\\n",
    "#                        top = -np.int(warp_matrix_max[2]), \\\n",
    "#                        left=-np.int(warp_matrix_max[0]), \\\n",
    "#                        right = hs_stack.data.shape[1]-np.int(warp_matrix_max[1]))\n",
    "    \n",
    "    hs_stack.fold()\n",
    "    \n",
    "    return warp_matrix_returned"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def align2D_cv_2stacks(hs_stack1, hs_stack2, warp_mode):\n",
    "    \n",
    "    hs_stack1.change_dtype('float32')\n",
    "    hs_stack2.change_dtype('float32')\n",
    "    \n",
    "    hs_stack1.unfold_navigation_space()\n",
    "    hs_stack2.unfold_navigation_space()\n",
    "         \n",
    "    # High pass filter using low pass and Gaussian blurring\n",
    "    filter_1 = ndimage.gaussian_filter(hs_stack1.data[0], 10)\n",
    "    # Convert Numpy hpf data in openCV format (3 channels)\n",
    "    img_1_hpf_cv = cv2.cvtColor(filter_1, cv2.COLOR_GRAY2BGR)\n",
    "    # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "    img_1_hpf_cv = cv2.cvtColor(img_1_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    #find the shape\n",
    "    sz = img_1_hpf_cv.shape\n",
    "    \n",
    "    #Mask, needed for findTransformECC (not in the previous version of opencv)\n",
    "#    mask = np.zeros(hs_stack.data[0].shape)\n",
    "#    mask[:,:] = 1\n",
    "#    mask[0,0] = 0\n",
    "    \n",
    "    #Translation ( MOTION_TRANSLATION ) : The first image can be shifted ( translated ) by (x , y) to obtain the second image. There are only two parameters x and y that we need to estimate.\n",
    "    #Euclidean ( MOTION_EUCLIDEAN ) : The first image is a rotated and shifted version of the second image. So there are three parameters — x, y and angle . You will notice in Figure 4, when a square undergoes Euclidean transformation, the size does not change, parallel lines remain parallel, and right angles remain unchanged after transformation.\n",
    "    #Affine ( MOTION_AFFINE ) : An affine transform is a combination of rotation, translation ( shift ), scale, and shear. This transform has six parameters. When a square undergoes an Affine transformation, parallel lines remain parallel, but lines meeting at right angles no longer remain orthogonal.\n",
    "    #Homography ( MOTION_HOMOGRAPHY ) : All the transforms described above are 2D transforms. They do not account for 3D effects. A homography transform on the other hand can account for some 3D effects ( but not all ). This transform has 8 parameters. A square when transformed using a Homography can change to any quadrilateral.\n",
    "    \n",
    "    #warp_mode = cv2.MOTION_TRANSLATION\n",
    "    \n",
    "    # Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "        warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "    else :\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        \n",
    "    warp_matrix_returned = np.empty((hs_stack1.data.shape[0], warp_matrix.shape[0], warp_matrix.shape[1]))\n",
    "    \n",
    "    # Specify the number of iterations.\n",
    "    number_of_iterations = 3000;\n",
    "    \n",
    "    # Specify the threshold of the increment\n",
    "    termination_eps = 1e-10;\n",
    "    \n",
    "    # Define termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)\n",
    "\n",
    "    for i in range (0,hs_stack1.data.shape[0]):\n",
    "        # High pass filter using low pass and Gaussian blurring \n",
    "        filter_1 = ndimage.gaussian_filter(hs_stack1.data[i], 10)\n",
    "        # Convert Numpy hpf data in openCV format (3 channels)\n",
    "        img_1_hpf_cv = cv2.cvtColor(filter_1, cv2.COLOR_GRAY2BGR)\n",
    "        # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "        img_1_hpf_cv = cv2.cvtColor(img_1_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        ### Idem for ref data\n",
    "        # High pass filter using low pass and Gaussian blurring         \n",
    "        filter_2 = ndimage.gaussian_filter(hs_stack2.data[i], 10)\n",
    "        # Convert Numpy hpf data in openCV format (3 channels)\n",
    "        img_2_hpf_cv = cv2.cvtColor(filter_2, cv2.COLOR_GRAY2BGR)\n",
    "        # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "        img_2_hpf_cv = cv2.cvtColor(img_2_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "        (cc, warp_matrix) = cv2.findTransformECC(img_1_hpf_cv,img_2_hpf_cv,warp_matrix, warp_mode, criteria)\n",
    "    \n",
    "        warp_matrix_returned[i,:,:] = warp_matrix\n",
    "        \n",
    "        print(str(i) +' / '+str(hs_stack1.data.shape[0]-1))\n",
    "              \n",
    "    hs_stack1.fold()\n",
    "    hs_stack2.fold()\n",
    "    \n",
    "    return warp_matrix_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quadrant(img, cent):\n",
    "    ABCD = np.empty(4)\n",
    "    vertical = np.int(img.shape[0]-cent[0])\n",
    "    horizontal = np.int(img.shape[1]-cent[1])\n",
    "    ABCD[0] = np.sum(img[0:vertical,0:horizontal])\n",
    "    ABCD[1] = np.sum(img[vertical:np.int(img.shape[0]),0:horizontal])\n",
    "    ABCD[2] = np.sum(img[0:vertical,horizontal:np.int(img.shape[1])])\n",
    "    ABCD[3] = np.sum(img[vertical:np.int(img.shape[0]),horizontal:np.int(img.shape[1])])\n",
    "    \n",
    "    return ABCD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
