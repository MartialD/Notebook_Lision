{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperspy notebook to generate video from a series of TEM image\n",
    "#### by Martial Duchamp NTU-MSE, Singapore m.duchamp@ntu.edu.sg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import csv\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import matplotlib.animation as animation\n",
    "import matplotlib as mpl\n",
    "from scipy import interpolate\n",
    "from scipy import ndimage\n",
    "#import numpy as np, cv2\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "mpl.rcParams['axes.linewidth'] = 3.0 #set the value globally\n",
    "#mpl.use(\"Agg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab qt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import sys \n",
    "#sys.path.insert(0, '/home/martial/Data/programs/Hyperspy_ungit')\n",
    "import hyperspy.api as hs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n    H y p e r S p y\\n    Version 1.5.2\\n\\n    http://www.hyperspy.org\\n\\n    '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hs.hyperspy.Release.info"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read TEM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = '/mnt/nisbfs/Vaso/2020-12-28/008_lowest-122ohms/'\n",
    "TEM = hs.load(path1+'80kX*ATT1*.dm4', stack=\"True\")\n",
    "\n",
    "path2 = '/mnt/nisbfs/Vaso/2020-12-28/009_127ohms-132ohms/'\n",
    "TEM.extend(hs.load(path2+'80kX*ATT1*.dm4', stack=\"True\"))\n",
    "\n",
    "path3 = '/mnt/nisbfs/Vaso/2020-12-28/010_137ohms-to-157ohms/'\n",
    "TEM.extend(hs.load(path3+'80kX*ATT1*.dm4', stack=\"True\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Signal2D, title: 80kX ATT1  0002-R=102ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0004 =105ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0005 R=112ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0006 R=117ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0007 R=122ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0008 R=127ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0010 R=132ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0012 R=137ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0013 R=142ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0014 R=147ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0015 R=152ohms, dimensions: (|1024, 1024)>,\n",
       " <Signal2D, title: 80kX ATT1  0016 R=157ohms, dimensions: (|1024, 1024)>]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM[1].metadata.General.original_filename = '80kX ATT1  0004 R=105ohms.dm4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R = b*T+c\n",
    "b =0.41\n",
    "c=39."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "FFMpegWriter = animation.writers['ffmpeg']\n",
    "metadata = dict(title='008_lowest-to-157ohms', artist='M. Duchamp')\n",
    "writer = FFMpegWriter(fps=0.5, metadata=metadata, bitrate=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=1, ncols=1)\n",
    "im = axes.imshow(ndimage.gaussian_filter(TEM[0].data,6), cmap='gray', \\\n",
    "                  vmin=0.3*np.mean(TEM[0].data), vmax=1.7*np.mean(TEM[0].data))\n",
    "\n",
    "textbox = plt.text(0.8, 0.8, \\\n",
    "    '{0:.0f}'.format((float(TEM[i].metadata.General.original_filename[18:21]) - c)/b) +'K', \\\n",
    "    fontsize=15, verticalalignment='top', backgroundcolor='white') \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n"
     ]
    }
   ],
   "source": [
    "with writer.saving(fig, \"008_lowest-to-157ohms.mp4\", dpi=300):\n",
    "    for i in range(0,TEM.count(0)):\n",
    "        im = axes.imshow(ndimage.gaussian_filter(TEM[i].data,6), cmap='gray', \\\n",
    "                         vmin=0.3*np.mean(TEM[i].data), vmax=1.7*np.mean(TEM[i].data))           \n",
    "        textbox = plt.text(0.8, 0.8, \\\n",
    "            '{0:.0f}'.format((float(TEM[i].metadata.General.original_filename[18:21]) - c)/b) +'K', \\\n",
    "            fontsize=15, verticalalignment='top', backgroundcolor='white')   \n",
    "        writer.grab_frame()\n",
    "        textbox.remove() \n",
    "        print(i)\n",
    "    for j in range(0,3):\n",
    "        im = axes.imshow(ndimage.gaussian_filter(TEM[i].data,6), cmap='gray', \\\n",
    "                         vmin=0.3*np.mean(TEM[i].data), vmax=1.7*np.mean(TEM[i].data))           \n",
    "        textbox = plt.text(0.8, 0.8, \\\n",
    "            '{0:.0f}'.format((float(TEM[i].metadata.General.original_filename[18:21]) - c)/b) +'K', \\\n",
    "            fontsize=15, verticalalignment='top', backgroundcolor='white')   \n",
    "        writer.grab_frame()\n",
    "        textbox.remove() \n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align2D_cv(hs_stack, warp_mode):\n",
    "    \n",
    "    hs_stack.change_dtype('float32')\n",
    "\n",
    "    #shift\n",
    "    warp_matrix_max = np.zeros(4)\n",
    "    \n",
    "    # High pass filter using low pass and Gaussian blurring\n",
    "    filter_1 = ndimage.gaussian_filter(hs_stack.data[0], 10)\n",
    "    \n",
    "    # Convert Numpy hpf data in openCV format (3 channels)\n",
    "    img_1_hpf_cv = cv2.cvtColor(filter_1, cv2.COLOR_GRAY2BGR)\n",
    "    # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "    img_1_hpf_cv = cv2.cvtColor(img_1_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "     \n",
    "    #find the shape\n",
    "    sz = img_1_hpf_cv.shape\n",
    "    \n",
    "    #Translation ( MOTION_TRANSLATION ) : The first image can be shifted ( translated ) by (x , y) to obtain the second image. There are only two parameters x and y that we need to estimate.\n",
    "    #Euclidean ( MOTION_EUCLIDEAN ) : The first image is a rotated and shifted version of the second image. So there are three parameters â€” x, y and angle . You will notice in Figure 4, when a square undergoes Euclidean transformation, the size does not change, parallel lines remain parallel, and right angles remain unchanged after transformation.\n",
    "    #Affine ( MOTION_AFFINE ) : An affine transform is a combination of rotation, translation ( shift ), scale, and shear. This transform has six parameters. When a square undergoes an Affine transformation, parallel lines remain parallel, but lines meeting at right angles no longer remain orthogonal.\n",
    "    #Homography ( MOTION_HOMOGRAPHY ) : All the transforms described above are 2D transforms. They do not account for 3D effects. A homography transform on the other hand can account for some 3D effects ( but not all ). This transform has 8 parameters. A square when transformed using a Homography can change to any quadrilateral.\n",
    "    \n",
    "    #warp_mode = cv2.MOTION_TRANSLATION\n",
    "    \n",
    "    # Define 2x3 or 3x3 matrices and initialize the matrix to identity\n",
    "    if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "        warp_matrix = np.eye(3, 3, dtype=np.float32)\n",
    "    else :\n",
    "        warp_matrix = np.eye(2, 3, dtype=np.float32)\n",
    "        \n",
    "    warp_matrix_returned = np.empty((hs_stack.data.shape[0], warp_matrix.shape[0], warp_matrix.shape[1]))\n",
    "    \n",
    "    # Specify the number of iterations.\n",
    "    number_of_iterations = 3000;\n",
    "    \n",
    "    # Specify the threshold of the increment\n",
    "    termination_eps = 1e-10;\n",
    "    \n",
    "    # Define termination criteria\n",
    "    criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, number_of_iterations,  termination_eps)\n",
    "\n",
    "    for i in range (1,hs_stack.data.shape[0]):\n",
    "        filter_2 = ndimage.gaussian_filter(hs_stack.data[i], 10)\n",
    "        # Convert Numpy hpf data in openCV format (3 channels)\n",
    "        img_2_hpf_cv = cv2.cvtColor(filter_2, cv2.COLOR_GRAY2BGR)\n",
    "        # Convert openCV format (3 channels) in openCV format grey (1 channel)\n",
    "        img_2_hpf_cv = cv2.cvtColor(img_2_hpf_cv, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "        # Run the ECC algorithm. The results are stored in warp_matrix.\n",
    "        (cc, warp_matrix) = cv2.findTransformECC(img_1_hpf_cv,img_2_hpf_cv,warp_matrix, warp_mode, criteria)\n",
    "    \n",
    "        warp_matrix_returned[i,:,:] = warp_matrix\n",
    "    \n",
    "        if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "            # Use warpPerspective for Homography \n",
    "            hs_stack.data[i] = cv2.warpPerspective (hs_stack.data[i], warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        else :\n",
    "            # Use warpAffine for Translation, Euclidean and Affine\n",
    "            hs_stack.data[i] = cv2.warpAffine(hs_stack.data[i], warp_matrix, (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP); \n",
    "           \n",
    "        if warp_matrix[0,2]<warp_matrix_max[0]:\n",
    "            warp_matrix_max[0]=warp_matrix[0,2]\n",
    "            \n",
    "        if warp_matrix[0,2]>warp_matrix_max[1]:\n",
    "            warp_matrix_max[1]=warp_matrix[0,2]\n",
    "\n",
    "        if warp_matrix[1,2]<warp_matrix_max[2]:\n",
    "            warp_matrix_max[2]=warp_matrix[1,2]\n",
    "            \n",
    "        if warp_matrix[1,2]>warp_matrix_max[3]:\n",
    "            warp_matrix_max[3]=warp_matrix[1,2]\n",
    "            \n",
    "        print(str(i) +' / '+str(hs_stack.data.shape[0]-1))\n",
    "            \n",
    "    hs_stack.crop_image(bottom=hs_stack.data.shape[2]-np.int(warp_matrix_max[3]), \\\n",
    "                        top = -np.int(warp_matrix_max[2]), \\\n",
    "                        left=-np.int(warp_matrix_max[0]), \\\n",
    "                        right = hs_stack.data.shape[1]-np.int(warp_matrix_max[1]))\n",
    "    \n",
    "    return warp_matrix_returned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align2D_cv_only_align(hs_stack, warp_matrix, warp_mode):\n",
    "    \n",
    "    hs_stack.change_dtype('float32')\n",
    "\n",
    "    #shift\n",
    "    warp_matrix_max = np.zeros(4)\n",
    "       \n",
    "    #find the shape\n",
    "    sz = hs_stack.data[0].shape\n",
    "        \n",
    "    for i in range (1,hs_stack.data.shape[0]):\n",
    "        if warp_mode == cv2.MOTION_HOMOGRAPHY :\n",
    "            # Use warpPerspective for Homography \n",
    "            hs_stack.data[i] = cv2.warpPerspective (hs_stack.data[i], warp_matrix[i,:,:], (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP)\n",
    "        else :\n",
    "            # Use warpAffine for Translation, Euclidean and Affine\n",
    "            hs_stack.data[i] = cv2.warpAffine(hs_stack.data[i], warp_matrix[i,:,:], (sz[1],sz[0]), flags=cv2.INTER_LINEAR + cv2.WARP_INVERSE_MAP); \n",
    "           \n",
    "        if warp_matrix[i,0,2]<warp_matrix_max[0]:\n",
    "            warp_matrix_max[0]=warp_matrix[i,0,2]\n",
    "            \n",
    "        if warp_matrix[i,0,2]>warp_matrix_max[1]:\n",
    "            warp_matrix_max[1]=warp_matrix[i,0,2]\n",
    "\n",
    "        if warp_matrix[i,1,2]<warp_matrix_max[2]:\n",
    "            warp_matrix_max[2]=warp_matrix[i,1,2]\n",
    "            \n",
    "        if warp_matrix[i,1,2]>warp_matrix_max[3]:\n",
    "            warp_matrix_max[3]=warp_matrix[i,1,2]\n",
    "            \n",
    "        print(str(i) +' / '+str(hs_stack.data.shape[0]-1))\n",
    " \n",
    "    hs_stack.crop_image(bottom=hs_stack.data.shape[2]-np.int(warp_matrix_max[3]), \\\n",
    "                        top = -np.int(warp_matrix_max[2]), \\\n",
    "                        left=-np.int(warp_matrix_max[0]), \\\n",
    "                        right = hs_stack.data.shape[1]-np.int(warp_matrix_max[1]))\n",
    "       \n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin4 = hs.load('16)_380K_bin4_ali.dm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin4.crop_image(top=80., left=20., bottom=115., right=100.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_matrix_returned_bin4 = align2D_cv(TEM_bin4, cv2.MOTION_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_matrix_returned_bin4 = np.load('warp_matrix_returned_bin4.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "np.save('warp_matrix_returned_bin4.npy',warp_matrix_returned_bin4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin4 = hs.load('16)_380K_bin4_ali.dm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "align2D_cv_only_align(TEM_bin4, warp_matrix_returned_bin4, cv2.MOTION_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin4.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_matrix_returned_bin2 = np.empty_like(warp_matrix_returned_bin4)\n",
    "warp_matrix_returned_bin2 = warp_matrix_returned_bin4\n",
    "warp_matrix_returned_bin2[:,0,2] = 2*warp_matrix_returned_bin4[:,0,2]\n",
    "warp_matrix_returned_bin2[:,1,2] = 2*warp_matrix_returned_bin4[:,1,2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin2 = hs.load('16)_380K_bin2_ali.dm4')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "align2D_cv_only_align(TEM_bin2, warp_matrix_returned_bin2, cv2.MOTION_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin2.save('TEM_bin2_aligned.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_bin2.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Not binned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM = hs.load('16)_380K_crop.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "warp_matrix_returned = align2D_cv(TEM, cv2.MOTION_TRANSLATION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.save('warp_matrix_returned.npy', warp_matrix_returned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FFT videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_croptr = hs.load('Extract_16)_380K_aligned_bin2_tr.dm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_croptr.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_croptr_fft = TEM_croptr.fft(shift=True, apodization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_croptr_fft.data = np.log(np.abs(TEM_croptr_fft.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM_cropbl = hs.load('Extract_16)_380K_aligned_bin2_bl.dm4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEM_cropbl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_cropbl_fft = TEM_cropbl.fft(shift=True, apodization=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM_cropbl_fft.data = np.log(np.abs(TEM_cropbl_fft.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TEM2 = hs.load('16)_380K_aligned_bin2.hdf5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "img_nbr=0\n",
    "grid = GridSpec(nrows=2, ncols=4, left=0.1, bottom=0.235, right=0.9, top=0.765, wspace=0.05, hspace=0.05)\n",
    "\n",
    "fig = plt.figure(0)\n",
    "fig.clf()\n",
    "rect1 = patches.Rectangle((912,149),512,512,linewidth=4,edgecolor='orange',facecolor='none', linestyle = '--')\n",
    "rect2 = patches.Rectangle((227,920),256,256,linewidth=4,edgecolor='purple',facecolor='none', linestyle = '--')\n",
    "\n",
    "ax1 = fig.add_subplot(grid[0:2, 0:2])\n",
    "plt.setp(ax1, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "im = ax1.imshow(TEM2.data[img_nbr], cmap='gray', vmin=0, vmax=2.7*np.mean(TEM2.data[img_nbr]))\n",
    "ax1.add_patch(rect1)\n",
    "ax1.add_patch(rect2)\n",
    "\n",
    "ax20 = fig.add_subplot(grid[0, 2])\n",
    "plt.setp(ax20, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax20.spines[pos].set_edgecolor('orange')\n",
    "im = ax20.imshow(TEM_croptr.data[img_nbr], cmap='gray', \\\n",
    "                vmin=0, \\\n",
    "                vmax=2.7*np.mean(TEM_croptr.data[img_nbr]))\n",
    "\n",
    "ax21 = fig.add_subplot(grid[0, 3])\n",
    "plt.setp(ax21, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax21.spines[pos].set_edgecolor('orange')\n",
    "im = ax21.imshow(TEM_croptr_fft.data[img_nbr], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[img_nbr]), \\\n",
    "                vmax=1.3*np.mean(TEM_croptr_fft.data[img_nbr]))\n",
    "ax21.arrow(354, 46, -17.5, 38, head_width=20., color='orange')\n",
    "  \n",
    "ax30 = fig.add_subplot(grid[1, 2])\n",
    "plt.setp(ax30, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax30.spines[pos].set_edgecolor('yellow')\n",
    "im = ax30.imshow(TEM_cropbl.data[img_nbr], cmap='gray', \\\n",
    "                vmin=0, \\\n",
    "                vmax=2.7*np.mean(TEM_cropbl.data[img_nbr]))\n",
    "    \n",
    "ax31 = fig.add_subplot(grid[1, 3])\n",
    "plt.setp(ax31, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax31.spines[pos].set_edgecolor('yellow')\n",
    "im = ax31.imshow(TEM_cropbl_fft.data[img_nbr], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[img_nbr]), \\\n",
    "                vmax=1.3*np.mean(TEM_cropbl_fft.data[img_nbr]))\n",
    "ax31.arrow(129, 47, -17.5/2, 38/2, head_width=20./2, color='purple')\n",
    "ax31.arrow(108, 23, -17.5/2, 38/2, head_width=20./2, color='orange')\n",
    "\n",
    "fig.savefig('TEM_exp16_nbr'+str(img_nbr)+'.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMG+FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'TEM_croptr_fft' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-d04488ce73fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpos\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'top'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'bottom'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'right'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'left'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0max21\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspines\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_edgecolor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'orange'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m im = ax21.imshow(TEM_croptr_fft.data[img_nbr], cmap='gray', \\\n\u001b[0m\u001b[1;32m     23\u001b[0m                 \u001b[0mvmin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTEM_croptr_fft\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mimg_nbr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m                 vmax=1.3*np.mean(TEM_croptr_fft.data[img_nbr]))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'TEM_croptr_fft' is not defined"
     ]
    }
   ],
   "source": [
    "img_nbr=107\n",
    "\n",
    "#fig = plt.figure(0)\n",
    "fig, axes = plt.subplots(nrows=2, ncols=3, sharex=False, sharey=False, squeeze=True, \\\n",
    "                         figsize=(8,6))#, gridspec_kw={'width_ratios': [1.2, 1]})\n",
    "grid = GridSpec(nrows=2, ncols=3, left=0.125, bottom=0.15, right=0.88, top=0.85, wspace=0.05, hspace=0.05)\n",
    "\n",
    "fig.clf()\n",
    "rect1 = patches.Rectangle((912,149),512,512,linewidth=4,edgecolor='orange',facecolor='none', linestyle = '--')\n",
    "rect2 = patches.Rectangle((227,920),256,256,linewidth=4,edgecolor='purple',facecolor='none', linestyle = '--')\n",
    "\n",
    "ax1 = fig.add_subplot(grid[0:2, 0:2])\n",
    "plt.setp(ax1, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "im = ax1.imshow(TEM2.data[img_nbr], cmap='gray', vmin=0, vmax=2.7*np.mean(TEM2.data[img_nbr]))\n",
    "ax1.add_patch(rect1)\n",
    "ax1.add_patch(rect2)\n",
    "\n",
    "ax21 = fig.add_subplot(grid[0, 2])\n",
    "plt.setp(ax21, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax21.spines[pos].set_edgecolor('orange')\n",
    "im = ax21.imshow(TEM_croptr_fft.data[img_nbr], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[img_nbr]), \\\n",
    "                vmax=1.3*np.mean(TEM_croptr_fft.data[img_nbr]))\n",
    "ax21.arrow(354, 46, -17.5, 38, head_width=20., color='orange')\n",
    "    \n",
    "ax31 = fig.add_subplot(grid[1, 2])\n",
    "plt.setp(ax31, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax31.spines[pos].set_edgecolor('purple')\n",
    "im = ax31.imshow(TEM_cropbl_fft.data[img_nbr], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[img_nbr]), \\\n",
    "                vmax=1.3*np.mean(TEM_cropbl_fft.data[img_nbr]))\n",
    "ax31.arrow(129, 47, -17.5/2, 38/2, head_width=20./2, color='purple')\n",
    "ax31.arrow(108, 23, -17.5/2, 38/2, head_width=20./2, color='orange')\n",
    "\n",
    "fig.savefig('TEM_exp16_nbr_small_'+str(img_nbr)+'.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMG no FFT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "img_nbr=19\n",
    "\n",
    "#fig = plt.figure(0)\n",
    "fig, axes = plt.subplots(nrows=1, ncols=2, sharex=False, sharey=False, squeeze=True, \\\n",
    "                         figsize=(8,6), gridspec_kw={'width_ratios': [5, 1]})\n",
    "grid = GridSpec(nrows=1, ncols=2, left=0.1, bottom=0.25, right=0.9, top=0.75, wspace=0.01, hspace=0.01)\n",
    "\n",
    "fig.clf()\n",
    "rect2 = patches.Rectangle((227,920),256,256,linewidth=4,edgecolor='purple',facecolor='none', linestyle = '--')\n",
    "\n",
    "ax1 = fig.add_subplot(grid[0, 0])\n",
    "plt.setp(ax1, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "im = ax1.imshow(TEM2.data[img_nbr], cmap='gray', vmin=0, vmax=2.7*np.mean(TEM2.data[img_nbr]))\n",
    "ax1.add_patch(rect2)\n",
    "   \n",
    "ax31 = fig.add_subplot(grid[0, 1])\n",
    "plt.setp(ax31, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax31.spines[pos].set_edgecolor('purple')\n",
    "im = ax31.imshow(TEM_cropbl.data[img_nbr], cmap='gray', \\\n",
    "                vmin=0.4*np.mean(TEM_cropbl.data[img_nbr]), \\\n",
    "                vmax=2*np.mean(TEM_cropbl.data[img_nbr]))\n",
    "\n",
    "fig.savefig('TEM_exp16_bl_'+str(img_nbr)+'.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Video FFT+graph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 366,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FFMpegWriter = animation.writers['ffmpeg']\n",
    "metadata = dict(title='Movie Test', artist='Matplotlib', comment='Movie support!')\n",
    "writer = FFMpegWriter(fps=5, metadata=metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 367,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 367,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpl.rcParams['axes.linewidth'] = 3.5 #set the value globally\n",
    "\n",
    "grid = GridSpec(nrows=3, ncols=3, left=0.125, bottom=0.1, right=0.9, top=0.95, wspace=0.05, hspace=0.1)\n",
    "fig = plt.figure(figsize=(6,6))\n",
    "fig.clf()\n",
    "\n",
    "rect1 = patches.Rectangle((912,149),512,512,linewidth=4,edgecolor='orange',facecolor='none', linestyle = '--')\n",
    "rect2 = patches.Rectangle((227,920),256,256,linewidth=4,edgecolor='yellow',facecolor='none', linestyle = '--')\n",
    "\n",
    "ax1 = fig.add_subplot(grid[0:2, 0:2])\n",
    "plt.setp(ax1, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "im = ax1.imshow(TEM2.data[img_nbr], cmap='gray', vmin=0, vmax=2.7*np.mean(TEM2.data[img_nbr]))\n",
    "ax1.add_patch(rect1)\n",
    "ax1.add_patch(rect2)\n",
    "\n",
    "ax21 = fig.add_subplot(grid[0, 2])\n",
    "plt.setp(ax21, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax21.spines[pos].set_edgecolor('orange')\n",
    "im = ax21.imshow(TEM_croptr_fft.data[img_nbr], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[img_nbr]), \\\n",
    "                vmax=1.3*np.mean(TEM_croptr_fft.data[img_nbr]))\n",
    "ax21.arrow(354, 46, -17.5, 38, head_width=20., color='orange')\n",
    "    \n",
    "ax31 = fig.add_subplot(grid[1, 2])\n",
    "plt.setp(ax31, xticks=[], xticklabels=[], yticks=[], yticklabels=[])\n",
    "for pos in ['top', 'bottom', 'right', 'left']:\n",
    "    ax31.spines[pos].set_edgecolor('yellow')\n",
    "im = ax31.imshow(TEM_cropbl_fft.data[img_nbr], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[img_nbr]), \\\n",
    "                vmax=1.3*np.mean(TEM_cropbl_fft.data[img_nbr]))\n",
    "ax31.arrow(129, 47, -17.5/2, 38/2, head_width=20./2, color='yellow')\n",
    "ax31.arrow(108, 23, -17.5/2, 38/2, head_width=20./2, color='orange')\n",
    "\n",
    "# x axis graph\n",
    "ax4 = fig.add_subplot(grid[2:3, 0:3])\n",
    "ax4.set_xlabel('Time [min]',fontsize=10)\n",
    "ax5 = ax4.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "# Voltage graph\n",
    "#ax4.plot(Tag_TEM_image[:,0]/60,Tag_TEM_image[:,1], color='red')\n",
    "#ax4.plot(Tag_TEM_image[:,0]/60, Tag_TEM_image[:,4], lw=5, color='red')\n",
    "ax4.set_ylabel('Voltage [mV]',fontsize=10)\n",
    "ax4.set_xlim(0, TEM2.data.shape[0]*20/60)\n",
    "ax4.set_ylim(np.min(Tag_TEM_image[:,1])*0.8, np.max(Tag_TEM_image[:,1])*1.2)\n",
    "\n",
    "# O2/H2 current graph\n",
    "#ax5.plot(Tag_TEM_image[:,0]/60-4,100*(Tag_TEM_image[:,2]/Tag_TEM_image[:,5] \\\n",
    "#         - np.min(Tag_TEM_image[:,2]/Tag_TEM_image[:,5])), lw=5, color='black')\n",
    "#ax5.plot(Tag_TEM_image[:,0]/60,100*(Tag_TEM_image[:,2]/Tag_TEM_image[:,5] \\\n",
    "#        - np.min(Tag_TEM_image[:,2]/Tag_TEM_image[:,5])), lw=5, dashes=[6, 2], color='black')\n",
    "ax5.set_ylabel('O$_2$/H$_2$ current ratio (x100)',fontsize=10)\n",
    "\n",
    "ax5.set_ylim(100*(np.min(Tag_TEM_image[:,2]/Tag_TEM_image[:,5] \\\n",
    "                - np.min(Tag_TEM_image[:,2]/Tag_TEM_image[:,5] ))), \\\n",
    "                100*(np.max(Tag_TEM_image[:,2]/Tag_TEM_image[:,5] \\\n",
    "                - np.min(Tag_TEM_image[:,2]/Tag_TEM_image[:,5]))*1.1))\n",
    "\n",
    "plt.setp(ax4.get_xticklabels(), fontsize=7)\n",
    "plt.setp(ax4.get_yticklabels(), fontsize=7)\n",
    "plt.setp(ax5.get_yticklabels(), fontsize=7)\n",
    "ax5.yaxis.set_ticks(np.arange(0, 4.5, 1))\n",
    "\n",
    "plt.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 over 160\n",
      "2 over 160\n",
      "3 over 160\n",
      "4 over 160\n",
      "5 over 160\n",
      "6 over 160\n",
      "7 over 160\n",
      "8 over 160\n",
      "9 over 160\n",
      "10 over 160\n",
      "11 over 160\n",
      "12 over 160\n",
      "13 over 160\n",
      "14 over 160\n",
      "15 over 160\n",
      "16 over 160\n",
      "17 over 160\n",
      "18 over 160\n",
      "19 over 160\n",
      "20 over 160\n",
      "21 over 160\n",
      "22 over 160\n",
      "23 over 160\n",
      "24 over 160\n",
      "25 over 160\n",
      "26 over 160\n",
      "27 over 160\n",
      "28 over 160\n",
      "29 over 160\n",
      "30 over 160\n",
      "31 over 160\n",
      "32 over 160\n",
      "33 over 160\n",
      "34 over 160\n",
      "35 over 160\n",
      "36 over 160\n",
      "37 over 160\n",
      "38 over 160\n",
      "39 over 160\n",
      "40 over 160\n",
      "41 over 160\n",
      "42 over 160\n",
      "43 over 160\n",
      "44 over 160\n",
      "45 over 160\n",
      "46 over 160\n",
      "47 over 160\n",
      "48 over 160\n",
      "49 over 160\n",
      "50 over 160\n",
      "51 over 160\n",
      "52 over 160\n",
      "53 over 160\n",
      "54 over 160\n",
      "55 over 160\n",
      "56 over 160\n",
      "57 over 160\n",
      "58 over 160\n",
      "59 over 160\n",
      "60 over 160\n",
      "61 over 160\n",
      "62 over 160\n",
      "63 over 160\n",
      "64 over 160\n",
      "65 over 160\n",
      "66 over 160\n",
      "67 over 160\n",
      "68 over 160\n",
      "69 over 160\n",
      "70 over 160\n",
      "71 over 160\n",
      "72 over 160\n",
      "73 over 160\n",
      "74 over 160\n",
      "75 over 160\n",
      "76 over 160\n",
      "77 over 160\n",
      "78 over 160\n",
      "79 over 160\n",
      "80 over 160\n",
      "81 over 160\n",
      "82 over 160\n",
      "83 over 160\n",
      "84 over 160\n",
      "85 over 160\n",
      "86 over 160\n",
      "87 over 160\n",
      "88 over 160\n",
      "89 over 160\n",
      "90 over 160\n",
      "91 over 160\n",
      "92 over 160\n",
      "93 over 160\n",
      "94 over 160\n",
      "95 over 160\n",
      "96 over 160\n",
      "97 over 160\n",
      "98 over 160\n",
      "99 over 160\n",
      "100 over 160\n",
      "101 over 160\n",
      "102 over 160\n",
      "103 over 160\n",
      "104 over 160\n",
      "105 over 160\n",
      "106 over 160\n",
      "107 over 160\n",
      "108 over 160\n",
      "109 over 160\n",
      "110 over 160\n",
      "111 over 160\n",
      "112 over 160\n",
      "113 over 160\n",
      "114 over 160\n",
      "115 over 160\n",
      "116 over 160\n",
      "117 over 160\n",
      "118 over 160\n",
      "119 over 160\n",
      "120 over 160\n",
      "121 over 160\n",
      "122 over 160\n",
      "123 over 160\n",
      "124 over 160\n",
      "125 over 160\n",
      "126 over 160\n",
      "127 over 160\n",
      "128 over 160\n",
      "129 over 160\n",
      "130 over 160\n",
      "131 over 160\n",
      "132 over 160\n",
      "133 over 160\n",
      "134 over 160\n",
      "135 over 160\n",
      "136 over 160\n",
      "137 over 160\n",
      "138 over 160\n",
      "139 over 160\n",
      "140 over 160\n",
      "141 over 160\n",
      "142 over 160\n",
      "143 over 160\n",
      "144 over 160\n",
      "145 over 160\n",
      "146 over 160\n",
      "147 over 160\n",
      "148 over 160\n",
      "149 over 160\n",
      "150 over 160\n",
      "151 over 160\n",
      "152 over 160\n",
      "153 over 160\n",
      "154 over 160\n",
      "155 over 160\n",
      "156 over 160\n",
      "157 over 160\n",
      "158 over 160\n",
      "159 over 160\n",
      "160 over 160\n"
     ]
    }
   ],
   "source": [
    "with writer.saving(fig, \"Day2_exp16_FFT.mp4\", dpi=300):\n",
    "    for i in range(1,TEM2.data.shape[0],1):\n",
    "        im = ax1.imshow(TEM2.data[i], cmap='gray', vmin=0, vmax=2.7*np.mean(TEM2.data[img_nbr]))\n",
    "        im = ax21.imshow(TEM_croptr_fft.data[i], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[i]), \\\n",
    "                vmax=1.3*np.mean(TEM_croptr_fft.data[i]))\n",
    "        im = ax31.imshow(TEM_cropbl_fft.data[i], cmap='gray', \\\n",
    "                vmin=np.mean(TEM_croptr_fft.data[i]), \\\n",
    "                vmax=1.3*np.mean(TEM_cropbl_fft.data[i]))\n",
    "        im = ax4.plot(Tag_TEM_image[:i,0]/60,Tag_TEM_image[:i,1], color='red')\n",
    "        im = ax4.plot(Tag_TEM_image[:i,0]/60, Tag_TEM_image[:i,4], lw=5, color='red')\n",
    "        im = ax5.plot(Tag_TEM_image[:i,0]/60-4,100*(Tag_TEM_image[:i,2]/Tag_TEM_image[:i,5] \\\n",
    "                 - np.min(Tag_TEM_image[:,2]/Tag_TEM_image[:,5])), lw=5, color='black')\n",
    "        im = ax5.plot(Tag_TEM_image[:i,0]/60,100*(Tag_TEM_image[:i,2]/Tag_TEM_image[:i,5] \\\n",
    "                - np.min(Tag_TEM_image[:,2]/Tag_TEM_image[:,5])), lw=5, dashes=[6, 2], color='black')\n",
    "        \n",
    "        textstr = '\\n'.join((\n",
    "            'Img nbr: ' + str(i),\n",
    "            'Time: ' + str(round(20*Tag_TEM_image[(i),3]/60,2)) +' min',\n",
    "            str(round(Tag_TEM_image[(i),1],2)) + '  V'))\n",
    "       \n",
    "        textbox = plt.text(20*40./60, 1, textstr, fontsize=7, verticalalignment='top', \\\n",
    "                           backgroundcolor='white')   \n",
    "        writer.grab_frame()\n",
    "        textbox.remove()\n",
    "        print(str(i) + ' over ' + str(TEM2.data.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
